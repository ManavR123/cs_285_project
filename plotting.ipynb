{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Visualization\n",
    "\n",
    "In this notebook, we visualize the results from the experiments we ran. In order to use this notebook, you must have run the script found under `deeptutor/scripts/run.py`, which should have generated a variety of pickle files in a directory named `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First, we import the necessasry variables and define useful global variables. Feel free to edit these global variables if you have your data stored in a different location or if you only ran a subset of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "data_dir = \"data\"\n",
    "n_eps = 100\n",
    "n_reps = 10\n",
    "reward_funcs = [\n",
    "    \"likelihood\", \n",
    "    \"log_likelihood\"\n",
    "]\n",
    "envs = [\n",
    "    \"EFC\",\n",
    "    \"HLR\",\n",
    "    \"DASH\"\n",
    "] \n",
    "tutor_builders = [\n",
    "    \"Random\",\n",
    "    \"Leitner\",\n",
    "    \"SuperMnemo\",\n",
    "    \"Threshold\",\n",
    "    \"GRUTRPO\",\n",
    "    \"MLPTRPO\",\n",
    "    \"PPO\",\n",
    "    \"DQN\",\n",
    "]\n",
    "rl_tutors = [\"DQN\", \"PPO\", \"MLPTRPO\", \"GRUTRPO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation\n",
    "\n",
    "In this next cell, we aggregate the data from all the experiments into a global data tensor in order to process the data more effciently. We create the $R$ tensor which has shape (# of environments * # of reward functions, # of tutors, # of items, # of seeds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.empty((len(envs) * len(reward_funcs), 0, n_eps, n_reps))\n",
    "for tutor in tutor_builders:\n",
    "    with open(os.path.join(data_dir, f\"{tutor}_reward_logs.pkl\"), \"rb\") as f:\n",
    "        rewards = pickle.load(f)[\"rewards\"]\n",
    "    temp = np.empty((0, 100, 10))\n",
    "    for env_name in envs:\n",
    "        for reward_func in reward_funcs:\n",
    "            env = (\n",
    "                env_name + \"-\" + (\"L\" if reward_func == \"likelihood\" else \"LL\")\n",
    "            )\n",
    "            if env in rewards:\n",
    "                temp = np.append(temp, (np.expand_dims(rewards[env], axis=0)), axis=0)\n",
    "    R = np.append(R, (np.expand_dims(temp, axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data\n",
    "\n",
    "Next, we want standard all of our data by substracting our the results from our RandomTutor from each experiment in order to set our RandomTutor as a baseline for all of our experiments. This allows us to more effectively compare results. We also define a few helper functions to normalize our data in terms of the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(R.shape[0]):\n",
    "    for j in range(R.shape[3]):\n",
    "        R[i, :, :, j] = 100 * (R[i, :, :, j] - R[i, 0, :, j]) / abs(R[i, 0, :, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_means = lambda x: np.nanmean(x, axis=1)\n",
    "r_stderrs = lambda x: np.nanstd(x, axis=1) / np.sqrt(np.count_nonzero(x, axis=1))\n",
    "r_mins = lambda x: r_means(x) - r_stderrs(x)  # np.nanmin(x, axis=1)\n",
    "r_maxs = lambda x: r_means(x) + r_stderrs(x)  # np.nanmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results\n",
    "\n",
    "Lastly, we plot our results and save each plot to a png file. We show error bars only for the RL algorithms as the other algorithms are relatively simple and don't exhibit much variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_of_env_name = {\n",
    "    \"EFC\": \"Exponential Forgetting Curve\",\n",
    "    \"HLR\": \"Half-Life Regression\",\n",
    "    \"DASH\": \"Generalized Power-Law\",\n",
    "}\n",
    "\n",
    "for h, env_name in enumerate(envs):\n",
    "    for m, reward_func in enumerate(reward_funcs):\n",
    "        k = h * len(reward_funcs) + m\n",
    "\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\n",
    "            \"Percent better than Random\\n(Reward: %s)\"\n",
    "            % reward_func.replace(\"_\", \"-\")\n",
    "            .replace(\"likelihood\", \"Likelihood\")\n",
    "            .replace(\"log\", \"Log\")\n",
    "        )\n",
    "        plt.title(\"Student Model: %s\" % title_of_env_name[env_name])\n",
    "\n",
    "        colors = [\"gray\", \"teal\", \"teal\", \"teal\", \"orange\", \"magenta\", \"lime\", \"blue\"]\n",
    "        styles = [\"dotted\", \"dashed\", \"dashdot\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\"]\n",
    "        for i, tutor_name in enumerate(tutor_builders):\n",
    "            if tutor_name in rl_tutors:\n",
    "                x = range(R.shape[2])\n",
    "                y1 = r_mins(R[k, i, :, :])\n",
    "                y2 = r_maxs(R[k, i, :, :])\n",
    "                plt.fill_between(\n",
    "                    x,\n",
    "                    y1,\n",
    "                    y2,\n",
    "                    where=y2 >= y1,\n",
    "                    facecolor=colors[i],\n",
    "                    interpolate=True,\n",
    "                    alpha=0.5,\n",
    "                    label=tutor_name,\n",
    "                )\n",
    "                plt.plot(r_means(R[k, i, :, :]), color=colors[i])\n",
    "            else:\n",
    "                plt.axhline(\n",
    "                    y=np.nanmean(R[k, i, :, :]),\n",
    "                    color=colors[i],\n",
    "                    linestyle=styles[i],\n",
    "                    label=tutor_name,\n",
    "                )\n",
    "\n",
    "        plt.yticks(plt.yticks()[0], [str(int(x)) + r\"%\" for x in plt.yticks()[0]])\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.savefig(\n",
    "            os.path.join(data_dir, \"plots\", \"%s-%s.png\" % (env_name, reward_func)),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
